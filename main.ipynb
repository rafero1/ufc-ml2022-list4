{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gerar gráficos\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Set:\n",
    "    def __init__(self, dataset, features, output):\n",
    "        self.dataset = dataset\n",
    "        self.features = features\n",
    "        self.output = output\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.dataset[:, self.features]\n",
    "    \n",
    "    def get_x_apply(self, func):\n",
    "        return func(self.dataset[:, self.features])\n",
    "\n",
    "    def set_x(self, new_x):\n",
    "        self.x = new_x\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.dataset[:, self.output]\n",
    "\n",
    "    def get_X(self, func=None):\n",
    "        if (func):\n",
    "            return np.c_[np.ones(self.get_n()), func(self.get_x())]\n",
    "        else:\n",
    "            return np.c_[np.ones(self.get_n()), self.get_x()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y >= 1\n",
    "\n",
    "def is_false_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y <= 0\n",
    "\n",
    "def is_true_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y <= 0\n",
    "\n",
    "def is_false_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y >= 1\n",
    "\n",
    "def confusion_matrix(y, y_pred):\n",
    "    \"\"\" returns (tp, fp, tn, fn) \"\"\"\n",
    "\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        tp += 1 if is_true_positive(y[i], pred) else 0\n",
    "        fp += 1 if is_false_positive(y[i], pred) else 0\n",
    "        tn += 1 if is_true_negative(y[i], pred) else 0\n",
    "        fn += 1 if is_false_negative(y[i], pred) else 0\n",
    "    return (tp, fp, tn, fn)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def precision(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y, y_pred):\n",
    "    precision_ = precision(y, y_pred)\n",
    "    recall_ = recall(y, y_pred)\n",
    "    return 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "\n",
    "def get_metrics(n_folds):\n",
    "    return {\n",
    "        \"accuracy\": np.zeros(n_folds),\n",
    "        \"precision\": np.zeros(n_folds),\n",
    "        \"recall\": np.zeros(n_folds),\n",
    "        \"f1_score\": np.zeros(n_folds)\n",
    "    }\n",
    "\n",
    "def calculate_metrics(metrics, y_test, y_pred):\n",
    "    metrics[\"accuracy\"][i] = (accuracy(y_test, y_pred))\n",
    "    metrics[\"precision\"][i] = (precision(y_test, y_pred))\n",
    "    metrics[\"recall\"][i] = (recall(y_test, y_pred))\n",
    "    metrics[\"f1_score\"][i] = (f1_score(y_test, y_pred))\n",
    "\n",
    "def print_metrics(metrics, name, n_folds):\n",
    "    print(\"%i-fold cross validation com %s\" % (n_folds, name))\n",
    "    print(\"acurácia: %.8f +/- %.8f\" % (metrics[\"accuracy\"].mean(), metrics[\"accuracy\"].std()))\n",
    "    print(\"revocação: %.8f +/- %.8f\" % (metrics[\"precision\"].mean(), metrics[\"precision\"].std()))\n",
    "    print(\"precisão: %.8f +/- %.8f\" % (metrics[\"recall\"].mean(), metrics[\"recall\"].std()))\n",
    "    print(\"f1-score: %.8f +/- %.8f\" % (metrics[\"f1_score\"].mean(), metrics[\"f1_score\"].std()))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(array, k = int):\n",
    "    \"\"\"realiza o split dos dados em k-folds\"\"\"\n",
    "    shuffled_data = np.random.permutation(array)\n",
    "    folds = np.array_split(shuffled_data, k)\n",
    "    return folds\n",
    "\n",
    "def k_fold_train_test(folds):\n",
    "    \"\"\"retorna um vetor com as configurações de treino e teste definidas pelo k-fold split\n",
    "\n",
    "    returns (i, train, test)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        train = np.vstack([x for j, x in enumerate(folds) if j != i])\n",
    "        test = fold\n",
    "        results.append((i, train, test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em **concrete.csv**, organizado em 9 colunas, sendo as 8 primeiras colunas os atributos e a última coluna a saída. Os 8 atributos referem-se à caracterização de diferentes tipos de concreto para construção civil. A saída é a resistência à compressão do concreto (em megapascals, MPa). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/4353."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('concrete.csv', delimiter=',')\n",
    "np.random.seed(666)\n",
    "features = np.arange(8)\n",
    "labels = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considere um modelo de regressão não linear baseado em redes neurais artificiais. Separe os dados aleatoriamente em treino, validação e teste (por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:\n",
    "\n",
    "- **MLP (multilayer perceptron)**: 1 camada oculta e treinamento em *minibatch* via gradiente descendente estocástico com termo de *momentum*. Utilize o conjunto de validação para a justar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Set(data, features, labels)\n",
    "train_X, test_validation_X, train_y, test_validation_y = model_selection.train_test_split(data.get_x_apply(func=stats.zscore), data.get_y(), test_size=0.4, random_state=666, shuffle=True)\n",
    "test_X, validation_X, test_y, validation_y = model_selection.train_test_split(test_validation_X, test_validation_y, test_size=0.5, random_state=666)\n",
    "\n",
    "def cross_entropy(y, y_pred):\n",
    "    return -1 * np.mean(y * np.log(y_pred))\n",
    "\n",
    "def mse(y, y_pred):\n",
    "    return np.mean((y - y_pred)**2)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivate(z):\n",
    "    return sigmoid(z) - sigmoid(z)**2\n",
    "\n",
    "def my_shuffle(X, Y):\n",
    "  shuffled = random.sample([X[i] + [Y[i]] for i in range(X.shape[0])], X.shape[0])\n",
    "  return np.array([i[:-1] for i in shuffled]), np.array([i[-1] for i in shuffled])\n",
    "  \n",
    "def my_shuffle_and_split(X, Y, B):\n",
    "  split = lambda x, B: np.array([x[i:i+B] for i in range(x.shape[0], B)])\n",
    "  X, Y = my_shuffle(X, Y)\n",
    "  X, Y = split(X, B), split(Y, B)\n",
    "  return [[X[i], Y[i]] for i in range(X.shape[0])]\n",
    "\n",
    "hidden_layer_nn = 2\n",
    "output_layer_nn = 1\n",
    "def multilayer_perceptron(X, y, batch_size, epochs, learning_rate):\n",
    "    random_weights = np.random.uniform(-1, 1, (hidden_layer_nn, X.shape[1]))\n",
    "    w = np.c_[np.ones((hidden_layer_nn, 1)), random_weights]\n",
    "    m = np.random.uniform(-1, 1, (output_layer_nn, hidden_layer_nn + 1))\n",
    "    errors = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        batches = my_shuffle_and_split(X, y, batch_size)\n",
    "        # batches = k_fold_split(np.c_[X, y], batch_size)\n",
    "        error_sum = 0\n",
    "\n",
    "        for x, y in batches:\n",
    "            x, y = np.c_[np.ones((len(x), 1)), x], np.array(y).T\n",
    "\n",
    "            # foward\n",
    "            u = np.dot(w, x.T).T\n",
    "            z = np.c_[(np.ones((len(x), 1)), sigmoid(u))]\n",
    "\n",
    "            r = np.dot(m, z.T)\n",
    "            o = sigmoid(r)\n",
    "\n",
    "            # backward\n",
    "            e = y - o\n",
    "            delta = np.multiply(e, sigmoid_derivate(r))\n",
    "            zeta = np.multiply(sigmoid_derivate(u), np.dot(m[:,1:].T, delta).T)\n",
    "\n",
    "            m += ((learning_rate/batch_size) * np.dot(delta, z))\n",
    "            w += ((learning_rate/batch_size) * np.dot(zeta.T, x))\n",
    "\n",
    "        errors.append(-(error_sum / X.shape[0]))\n",
    "    \n",
    "    # print(errors)\n",
    "    # plt.plot(range(epochs), errors)\n",
    "    # plt.xlabel(\"epochs\")\n",
    "    # plt.ylabel('error')\n",
    "    # plt.show()\n",
    "  \n",
    "    return w.tolist(), m.tolist()\n",
    "\n",
    "w, m = multilayer_perceptron(train_X, train_y, 20, 300, 0.1)\n",
    "# print(len(w), \"x\", len(w[0])), print(w)\n",
    "# print(len(m), \"x\", len(m[0])), print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Apresente as curvas da função custo nos conjuntos de treinamento e validação ao longo das épocas. Reporte também para os conjuntos de treino, validação e teste as métricas abaixo:\n",
    "- **RMSE (root mean squared error)**: \n",
    "- **MAE (mean absolute error)**:\n",
    "- **MRE (mean relative error)**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em **vowel.csv**, organizado em 11 colunas, sendo as 10 primeiras colunas os atributos e a última coluna a saída. Os 10 atributos referem-se à caracterização de amostras da fala de britânicos. A saída é o fonema de vogal correspondente, dentre as 11 possibilidades. Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/307."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('vowel.csv', delimiter=',')\n",
    "np.random.seed(666)\n",
    "features = np.arange(11)\n",
    "output = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considere um mo delo de classificação não linear baseado em redes neurais artificiais. Separe os dados aleatoriamente em treino, validação e teste (por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:\n",
    "\n",
    "- **MLP (multilayer perceptron)**: 1 camada o culta e treinamento em *minibatch* via gradiente descendente esto cástico com termo de *momentum*. Utilize o conjunto de validação para a justar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Apresente as curvas da função custo nos conjuntos de treinamento e validação ao longo das épocas. Reporte também a acurácia obtida para os conjuntos de treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb9fab3fdb8fd2bead71da85ccfeac548509469d73b057c59d3c3662b7f76c46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
