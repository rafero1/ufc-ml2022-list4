{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gerar gráficos\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Set:\n",
    "    def __init__(self, dataset, features, output):\n",
    "        self.dataset = dataset\n",
    "        self.features = features\n",
    "        self.output = output\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.dataset[:, self.features]\n",
    "    \n",
    "    def get_x_apply(self, func):\n",
    "        return func(self.dataset[:, self.features])\n",
    "\n",
    "    def set_x(self, new_x):\n",
    "        self.x = new_x\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.dataset[:, self.output]\n",
    "\n",
    "    def get_X(self, func=None):\n",
    "        if (func):\n",
    "            return np.c_[np.ones(self.get_n()), func(self.get_x())]\n",
    "        else:\n",
    "            return np.c_[np.ones(self.get_n()), self.get_x()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y >= 1\n",
    "\n",
    "def is_false_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y <= 0\n",
    "\n",
    "def is_true_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y <= 0\n",
    "\n",
    "def is_false_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y >= 1\n",
    "\n",
    "def confusion_matrix(y, y_pred):\n",
    "    \"\"\" returns (tp, fp, tn, fn) \"\"\"\n",
    "\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        tp += 1 if is_true_positive(y[i], pred) else 0\n",
    "        fp += 1 if is_false_positive(y[i], pred) else 0\n",
    "        tn += 1 if is_true_negative(y[i], pred) else 0\n",
    "        fn += 1 if is_false_negative(y[i], pred) else 0\n",
    "    return (tp, fp, tn, fn)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def precision(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y, y_pred):\n",
    "    tp, fp, tn, fn = confusion_matrix(y, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y, y_pred):\n",
    "    precision_ = precision(y, y_pred)\n",
    "    recall_ = recall(y, y_pred)\n",
    "    return 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "\n",
    "def get_metrics(n_folds):\n",
    "    return {\n",
    "        \"accuracy\": np.zeros(n_folds),\n",
    "        \"precision\": np.zeros(n_folds),\n",
    "        \"recall\": np.zeros(n_folds),\n",
    "        \"f1_score\": np.zeros(n_folds)\n",
    "    }\n",
    "\n",
    "def calculate_metrics(metrics, y_test, y_pred):\n",
    "    metrics[\"accuracy\"][i] = (accuracy(y_test, y_pred))\n",
    "    metrics[\"precision\"][i] = (precision(y_test, y_pred))\n",
    "    metrics[\"recall\"][i] = (recall(y_test, y_pred))\n",
    "    metrics[\"f1_score\"][i] = (f1_score(y_test, y_pred))\n",
    "\n",
    "def print_metrics(metrics, name, n_folds):\n",
    "    print(\"%i-fold cross validation com %s\" % (n_folds, name))\n",
    "    print(\"acurácia: %.8f +/- %.8f\" % (metrics[\"accuracy\"].mean(), metrics[\"accuracy\"].std()))\n",
    "    print(\"revocação: %.8f +/- %.8f\" % (metrics[\"precision\"].mean(), metrics[\"precision\"].std()))\n",
    "    print(\"precisão: %.8f +/- %.8f\" % (metrics[\"recall\"].mean(), metrics[\"recall\"].std()))\n",
    "    print(\"f1-score: %.8f +/- %.8f\" % (metrics[\"f1_score\"].mean(), metrics[\"f1_score\"].std()))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(array, k = int):\n",
    "    \"\"\"realiza o split dos dados em k-folds\"\"\"\n",
    "    shuffled_data = np.random.permutation(array)\n",
    "    folds = np.array_split(shuffled_data, k)\n",
    "    return folds\n",
    "\n",
    "def k_fold_train_test(folds):\n",
    "    \"\"\"retorna um vetor com as configurações de treino e teste definidas pelo k-fold split\n",
    "\n",
    "    returns (i, train, test)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        train = np.vstack([x for j, x in enumerate(folds) if j != i])\n",
    "        test = fold\n",
    "        results.append((i, train, test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em **concrete.csv**, organizado em 9 colunas, sendo as 8 primeiras colunas os atributos e a última coluna a saída. Os 8 atributos referem-se à caracterização de diferentes tipos de concreto para construção civil. A saída é a resistência à compressão do concreto (em megapascals, MPa). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/4353."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('concrete.csv', delimiter=',')\n",
    "np.random.seed(666)\n",
    "features = np.arange(8)\n",
    "labels = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considere um modelo de regressão não linear baseado em redes neurais artificiais. Separe os dados aleatoriamente em treino, validação e teste (por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:\n",
    "\n",
    "- **MLP (multilayer perceptron)**: 1 camada oculta e treinamento em *minibatch* via gradiente descendente estocástico com termo de *momentum*. Utilize o conjunto de validação para a justar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,619) and (9,20) not aligned: 619 (dim 1) != 9 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16588/1325315347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultilayer_perceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16588/1325315347.py\u001b[0m in \u001b[0;36mmultilayer_perceptron\u001b[1;34m(X, y, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;34m\"\"\" FORWARD \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,619) and (9,20) not aligned: 619 (dim 1) != 9 (dim 0)"
     ]
    }
   ],
   "source": [
    "data = Set(data, features, labels)\n",
    "train_X, test_validation_X, train_y, test_validation_y = model_selection.train_test_split(data.get_X(func=stats.zscore), data.get_y(), test_size=0.4, random_state=666, shuffle=True)\n",
    "test_X, validation_X, test_y, validation_y = model_selection.train_test_split(test_validation_X, test_validation_y, test_size=0.5, random_state=666)\n",
    "\n",
    "def cross_entropy(y, y_pred):\n",
    "    return -1 * np.mean(y * np.log(y_pred))\n",
    "\n",
    "def mse(y, y_pred):\n",
    "    return np.mean((y - y_pred)**2)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivate(z):\n",
    "    return sigmoid(z) - sigmoid(z)**2\n",
    "\n",
    "def my_shuffle(X, Y):\n",
    "  shuffled = random.sample([X[i] + [Y[i]] for i in range(len(X))], len(X))\n",
    "  return [i[:-1] for i in shuffled], [i[-1] for i in shuffled]\n",
    "  \n",
    "def my_shuffle_and_split(X, Y, B):\n",
    "  split = lambda x,B: [x[i:i+B] for i in range(0,len(x),B)]\n",
    "  X, Y = my_shuffle(X, Y)\n",
    "  X, Y = split(X, B), split(Y, B)\n",
    "  return [[X[i],Y[i]] for i in range(len(X))]\n",
    "\n",
    "hidden_layer_nn = 2\n",
    "output_layer_nn = 1\n",
    "def multilayer_perceptron(X, y, batch_size, epochs, learning_rate):\n",
    "    w = np.c_[np.ones((hidden_layer_nn, 1)), np.random.uniform(-1, 1, (hidden_layer_nn, X.shape[0]))]\n",
    "    m = np.random.uniform(-1, 1, (output_layer_nn, hidden_layer_nn + 1))\n",
    "    errors = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        groups = my_shuffle_and_split(X, y, batch_size)\n",
    "        error_sum = 0\n",
    "\n",
    "        for x, y in groups:\n",
    "            x, y = np.c_[np.ones((len(x), 1)), x], np.array(y).T\n",
    "\n",
    "            \"\"\" FORWARD \"\"\"\n",
    "            u = np.dot(w, x.T).T\n",
    "            z = np.hstack((np.ones((len(x),1)), sigmoid(u)))\n",
    "\n",
    "            r = np.dot(m, z.T)\n",
    "            o = sigmoid(r)\n",
    "\n",
    "            #sum_error += np.sum(np.dot(y.T, np.log(o)))\n",
    "\n",
    "            \"\"\" BACKWARD \"\"\"\n",
    "            e = y - o\n",
    "            delta = np.multiply(e, sigmoid_derivate(r))\n",
    "            zeta = np.multiply(sigmoid_derivate(u), np.dot(m[:,1:].T, delta).T)\n",
    "\n",
    "            m += ((learning_rate/batch_size) * np.dot(delta, z))\n",
    "            w += ((learning_rate/batch_size) * np.dot(zeta.T, x))\n",
    "        errors.append(-(error_sum / X.shape[0]))\n",
    "    plt.plot(range(epochs), errors)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "  \n",
    "    return w.tolist(), m.tolist()\n",
    "\n",
    "w, m = multilayer_perceptron(train_X, train_y, 20, 300, 0.1)\n",
    "print(len(w), \"x\", len(w[0])), print(w)\n",
    "print(len(m), \"x\", len(m[0])), print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Apresente as curvas da função custo nos conjuntos de treinamento e validação ao longo das épocas. Reporte também para os conjuntos de treino, validação e teste as métricas abaixo:\n",
    "- **RMSE (root mean squared error)**: \n",
    "- **MAE (mean absolute error)**:\n",
    "- **MRE (mean relative error)**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em **vowel.csv**, organizado em 11 colunas, sendo as 10 primeiras colunas os atributos e a última coluna a saída. Os 10 atributos referem-se à caracterização de amostras da fala de britânicos. A saída é o fonema de vogal correspondente, dentre as 11 possibilidades. Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/307."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('vowel.csv', delimiter=',')\n",
    "np.random.seed(666)\n",
    "features = np.arange(11)\n",
    "output = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considere um mo delo de classificação não linear baseado em redes neurais artificiais. Separe os dados aleatoriamente em treino, validação e teste (por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:\n",
    "\n",
    "- **MLP (multilayer perceptron)**: 1 camada o culta e treinamento em *minibatch* via gradiente descendente esto cástico com termo de *momentum*. Utilize o conjunto de validação para a justar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Apresente as curvas da função custo nos conjuntos de treinamento e validação ao longo das épocas. Reporte também a acurácia obtida para os conjuntos de treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77ab0bf75426114283fafc7207ca0245f7de4738c2866fb9aad708a7843cc047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
